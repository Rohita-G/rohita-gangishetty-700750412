{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIByZJiR8JVbOCm/B0PlCV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohita-G/rohita-gangishetty-700750412/blob/main/icp6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozaqgOVS30aQ",
        "outputId": "11609141-5d97-48b3-84aa-86bcb2980f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/diabetes.csv'"
      ],
      "metadata": {
        "id": "sbnuTIjD4onP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "dataset = np.random.rand(100, 8)\n",
        "target = np.random.randint(2, size=100)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset, target, test_size=0.25, random_state=87)\n",
        "\n",
        "# Create a Sequential model\n",
        "my_nn = Sequential()\n",
        "\n",
        "# Add input layer and the first hidden layer\n",
        "my_nn.add(Dense(20, input_dim=8, activation='relu'))\n",
        "\n",
        "# Add additional Dense layers\n",
        "my_nn.add(Dense(32, activation='relu'))\n",
        "my_nn.add(Dense(64, activation='relu'))\n",
        "my_nn.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "my_nn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "my_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "my_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "# Print model summary and evaluate on the test data\n",
        "print(my_nn.summary())\n",
        "print(my_nn.evaluate(X_test, Y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDU2gKbP4t1i",
        "outputId": "d13e8025-3fc9-4b33-b988-edfad09f9abb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 2s 8ms/step - loss: 0.7002 - accuracy: 0.4933\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.4933\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.4933\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.4933\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 0.4933\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.4933\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.4933\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.5600\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.6667\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6833 - accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6825 - accuracy: 0.7200\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.7067\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.6933\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6783 - accuracy: 0.6933\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.6800\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6752 - accuracy: 0.6800\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6732 - accuracy: 0.7067\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.7067\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6684 - accuracy: 0.6933\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6658 - accuracy: 0.6933\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6624 - accuracy: 0.7067\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.6800\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6555 - accuracy: 0.7067\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6529 - accuracy: 0.6933\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6477 - accuracy: 0.7067\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6440 - accuracy: 0.6933\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.6800\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6342 - accuracy: 0.6800\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.6933\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6220 - accuracy: 0.7200\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.7067\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6133 - accuracy: 0.7200\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.6064 - accuracy: 0.7200\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.7200\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5961 - accuracy: 0.7067\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.6800\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5834 - accuracy: 0.7067\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.7067\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.7333\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5611 - accuracy: 0.7333\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5554 - accuracy: 0.7067\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7333\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7333\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5368 - accuracy: 0.7600\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7467\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7733\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7600\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7600\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.7333\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7733\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7733\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7733\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7733\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7867\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7867\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7867\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7600\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.8267\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.8133\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8133\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8133\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8400\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8400\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8533\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8533\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8667\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8800\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8667\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.3655 - accuracy: 0.8933\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3616 - accuracy: 0.8933\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3535 - accuracy: 0.8800\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8933\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8933\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8933\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3291 - accuracy: 0.8800\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3218 - accuracy: 0.8933\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3199 - accuracy: 0.9067\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.3070 - accuracy: 0.9067\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.9067\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.9200\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.9333\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2903 - accuracy: 0.9067\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2806 - accuracy: 0.9200\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2691 - accuracy: 0.9200\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2609 - accuracy: 0.9200\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2555 - accuracy: 0.9200\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2548 - accuracy: 0.9067\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.9200\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2388 - accuracy: 0.9467\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.9200\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9333\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2221 - accuracy: 0.9333\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2193 - accuracy: 0.9467\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2131 - accuracy: 0.9467\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2066 - accuracy: 0.9467\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1997 - accuracy: 0.9467\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9333\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1984 - accuracy: 0.9333\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_61 (Dense)            (None, 20)                180       \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 32)                672       \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5077 (19.83 KB)\n",
            "Trainable params: 5077 (19.83 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 1.3831 - accuracy: 0.4400\n",
            "[1.3830859661102295, 0.4399999976158142]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDbeKxss7BOK",
        "outputId": "3d0898c2-9b4d-4173-ad2e-d97e9ac98e74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 8s 31ms/step - loss: 0.2932 - accuracy: 0.9102 - val_loss: 0.2585 - val_accuracy: 0.9261\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0999 - accuracy: 0.9690 - val_loss: 0.1357 - val_accuracy: 0.9584\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0643 - accuracy: 0.9800 - val_loss: 0.0892 - val_accuracy: 0.9719\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.0785 - val_accuracy: 0.9761\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.0833 - val_accuracy: 0.9748\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0614 - val_accuracy: 0.9829\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0661 - val_accuracy: 0.9824\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0729 - val_accuracy: 0.9822\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0707 - val_accuracy: 0.9818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "\n",
        "# Process the data\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0], dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0], dimData)\n",
        "\n",
        "# Convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "train_data /= 255.0\n",
        "test_data /= 255.0\n",
        "\n",
        "# Change the labels from integer to one-hot encoding.\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "# Creating a network with 3 hidden layers using 'tanh' activation\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='tanh', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dafvINU69ryv",
        "outputId": "0e4da6e5-c983-407a-c7f4-0f4140d0b3e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.3419 - accuracy: 0.8967 - val_loss: 0.2382 - val_accuracy: 0.9246\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.1516 - accuracy: 0.9544 - val_loss: 0.1265 - val_accuracy: 0.9602\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1035 - accuracy: 0.9684 - val_loss: 0.1234 - val_accuracy: 0.9604\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 0.1181 - val_accuracy: 0.9617\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0564 - accuracy: 0.9832 - val_loss: 0.0924 - val_accuracy: 0.9702\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.0744 - val_accuracy: 0.9772\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.0778 - val_accuracy: 0.9761\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0641 - val_accuracy: 0.9804\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0691 - val_accuracy: 0.9787\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0672 - val_accuracy: 0.9789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "\n",
        "# Process the data\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0], dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0], dimData)\n",
        "\n",
        "# Convert data to float (no scaling)\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "# Change the labels from integer to one-hot encoding.\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "# Creating a network with 3 hidden layers using 'tanh' activation\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='tanh', input_shape=(dimData,)))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45uoDbb0-9tT",
        "outputId": "b76008c0-0312-4b1b-80da-e776e1270dc8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "784\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 7s 27ms/step - loss: 0.3914 - accuracy: 0.8778 - val_loss: 0.2690 - val_accuracy: 0.9169\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.2085 - accuracy: 0.9356 - val_loss: 0.1820 - val_accuracy: 0.9425\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.1610 - accuracy: 0.9517 - val_loss: 0.1912 - val_accuracy: 0.9391\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.1430 - accuracy: 0.9553 - val_loss: 0.2168 - val_accuracy: 0.9319\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.1257 - accuracy: 0.9608 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.1114 - accuracy: 0.9655 - val_loss: 0.1512 - val_accuracy: 0.9516\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.1021 - accuracy: 0.9678 - val_loss: 0.1125 - val_accuracy: 0.9650\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0963 - accuracy: 0.9701 - val_loss: 0.1309 - val_accuracy: 0.9605\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0905 - accuracy: 0.9713 - val_loss: 0.1092 - val_accuracy: 0.9657\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0835 - accuracy: 0.9735 - val_loss: 0.1096 - val_accuracy: 0.9661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "index = np.random.randint(0, len(test_data))\n",
        "sample_image = test_data[index]\n",
        "sample_label = test_labels[index]\n",
        "sample_image = sample_image.reshape(1, -1)\n",
        "predicted_probs = model.predict(sample_image)\n",
        "predicted_class = np.argmax(predicted_probs)\n",
        "plt.imshow(sample_image.reshape(28, 28), cmap='gray')\n",
        "plt.title(f\"True Label: {sample_label}, Predicted Label: {predicted_class}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "Zk7wx5b4_l_Q",
        "outputId": "7eeba13e-492b-4679-ec56-d1f44b388df5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 382ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}